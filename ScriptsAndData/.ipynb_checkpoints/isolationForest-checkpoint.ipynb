{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar funciones de la librer√≠a de python data analysis\n",
    "import pandas as pd \n",
    "\n",
    "# Leer csv con datos y cargar en el dataframe data\n",
    "data = pd.read_csv(\"data/creditcard.csv\") \n",
    "\n",
    "# Preview de las 5 primeras filas de data, total filas: 284807\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total confirmado como fraude (class=1): 492\n",
    "data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# train con % de registros con Class=0\n",
    "n = 1000\n",
    "X_train = data[data[\"Class\"]==0].iloc[0:n,0:30]\n",
    "\n",
    "# test1 492 registros con Class=1, y_test1 colocamos -1 para poder comparar con score de clasificacion\n",
    "# test0 500 registros con Class=0 (disjunto de train), y_test0 colocamos 0 para poder comparar con score de clasificacion\n",
    "X_test1 = data[data[\"Class\"]==1].iloc[:,0:30]\n",
    "y_test1 = data[data[\"Class\"]==1].iloc[:,30:31]\n",
    "y_test1['Class']=-1\n",
    "X_test0 = data[data[\"Class\"]==0].iloc[n:n+500,0:30]\n",
    "y_test0 = data[data[\"Class\"]==0].iloc[n:n+500,30:31]\n",
    "y_test0['Class']=1\n",
    "\n",
    "# unificar test\n",
    "X_test = pd.concat([X_test1,X_test0], axis=0)\n",
    "y_test = pd.concat([y_test1,y_test0], axis=0)\n",
    "\n",
    "# fit the model\n",
    "clf = IsolationForest(behaviour='new', max_samples=100, n_estimators=100,\n",
    "                      random_state=1, contamination='auto')\n",
    "clf.fit(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = pd.DataFrame(zip(y_test['Class'],y_pred_test), \n",
    "                  columns=['actual test','score pred test'])\n",
    "\n",
    "#dtest[dtest['score pred test']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(dtest['actual test'], dtest['score pred test']))\n",
    "metrics.precision_recall_fscore_support(dtest['actual test'], dtest['score pred test'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dtest['actual test'], dtest['score pred test'], \n",
    "            rownames=['actual'], \n",
    "            colnames=['pred'], margins=False, margins_name=\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
